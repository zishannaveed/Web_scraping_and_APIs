{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_data(cities):\n",
    "    list_df = []\n",
    "    for city in cities:\n",
    "        # find url and store it in a variable\n",
    "        url = f\"https://en.wikipedia.org/wiki/{city}\"\n",
    "\n",
    "        # download html with a get request\n",
    "        headers = {\"Accept-Language\": \"en-US,en;q=0.8\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.status_code  # 200 status code means OK!\n",
    "\n",
    "        # parse html (create the 'soup')\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # find the table with the class 'infobox ib-settlement vcard'\n",
    "        table = soup.find(\"table\", {\"class\": \"infobox ib-settlement vcard\"})\n",
    "\n",
    "        # create a dictionary to store the data\n",
    "        res_dic = {}\n",
    "\n",
    "        # locate the div tag that contains the name of the city and extract the text\n",
    "        res_dic[\"city\"] = table.select(\"div.fn.org\")[0].text\n",
    "\n",
    "        # locate the div tag that contains the country and extract the text\n",
    "        res_dic[\"country\"] = table.select(\"td.infobox-data\")[0].text\n",
    "\n",
    "        # locate all the th and td elements\n",
    "        elements = table.find_all(\n",
    "            [\"th\", \"td\"], {\"class\": [\"infobox-header\", \"infobox-data\"]}\n",
    "        )\n",
    "        elements1 = table.find_all(\n",
    "            [\"th\", \"td\"], {\"class\": [\"infobox-label\", \"infobox-data\"]}\n",
    "        )\n",
    "        population = \"\"\n",
    "\n",
    "        # iterate through the elements and extract the population\n",
    "        for index, element in enumerate(elements):\n",
    "            if element.name == \"th\" and \"Population\" in element.text:\n",
    "                population = (\n",
    "                    elements[index + 1].text.replace(\",\", \"\").replace(\"[1]\", \"\")\n",
    "                )\n",
    "                break\n",
    "        # population is not always in the same place, so if it is not found in the first \n",
    "        # iteration, we look for it in the second iteration\n",
    "        # it was not in 'infobox-header' class, so we look for it in 'infobox-label' class\n",
    "        if population == \"\":\n",
    "            for index1, element1 in enumerate(elements1):\n",
    "                if element1.name == \"th\" and \"Population\" in element1.text:\n",
    "                    population = (\n",
    "                        elements1[index1 + 1].text.replace(\",\", \"\").replace(\"[1]\", \"\")\n",
    "                    )\n",
    "                    break\n",
    "        res_dic[\"population\"] = population\n",
    "\n",
    "        # locate the span element that contains the latitude and extract the text\n",
    "        latitude = (\n",
    "            table.select(\"span.latitude\")[0]\n",
    "            .text.replace(\"°\", \".\")\n",
    "            .replace(\"″\", \"\")\n",
    "            .replace(\"′\", \"\")\n",
    "        )\n",
    "        res_dic[\"latitude\"] = re.split(\"[a-zA-Z]\", latitude)[0]\n",
    "\n",
    "        # locate the span element that contains the latitude and extract the text\n",
    "        longitude = (\n",
    "            table.select(\"span.longitude\")[0]\n",
    "            .text.replace(\"°\", \".\")\n",
    "            .replace(\"″\", \"\")\n",
    "            .replace(\"′\", \"\")\n",
    "        )\n",
    "        res_dic[\"longitude\"] = re.split(\"[a-zA-Z]\", longitude)[0]\n",
    "        list_df.append(res_dic)\n",
    "    df = pd.DataFrame(list_df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cities=['Berlin','London','Paris','Madrid','Milan','Munich']\n",
    "df=wiki_data(list_of_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=\"db_weather_flights\"   # name of the database you want to use here\n",
    "host='Your Host ID'           # to connect to your local server\n",
    "user=\"root\"\n",
    "password='PASSWORD'           # your password!!!!\n",
    "port=3306\n",
    "con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('cities',                # 'cities'-> table name;\n",
    "              if_exists='append',  # if_exists -> will create new table if doesn't exist, \n",
    "                                   #otherwise, 'append' - will append data to existing table;\n",
    "              con=con,             # con-> connection string;\n",
    "              index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "033306f7acb5b229abd71b38a98b69899b85a5e011b812f9c1237c1eb3a45fd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
